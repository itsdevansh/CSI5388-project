{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b7571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cff6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #so the maximum number of columns are displayed in .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adf6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devansh\\AppData\\Local\\Temp\\ipykernel_1544\\2565550375.py:2: DtypeWarning: Columns (56,58,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"Android_Malware.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset on a datafdrame data\n",
    "data = pd.read_csv(\"Android_Malware.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34af53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [i.strip() for i in data.columns] # stripping all the whitespaces from the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bc3c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0        0\n",
      "Flow ID           1\n",
      "Source IP         0\n",
      "Source Port       0\n",
      "Destination IP    0\n",
      "                 ..\n",
      "Idle Mean         4\n",
      "Idle Std          4\n",
      "Idle Max          4\n",
      "Idle Min          4\n",
      "Label             0\n",
      "Length: 86, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f19373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Android_Adware and Android_Scareware\n",
    "data['Label'].unique()\n",
    "labels_to_remove = ['Android_Adware', 'Android_Scareware']\n",
    "data = data[~data['Label'].isin(labels_to_remove)]\n",
    "for column in data.columns:\n",
    "    if 'Timestamp' in column:\n",
    "        data = data.drop(column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7334d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 value :  Bwd PSH Flags\n",
      "Only 1 value :  Fwd URG Flags\n",
      "Only 1 value :  Bwd URG Flags\n",
      "Only 1 value :  RST Flag Count\n",
      "Same Unique Values :  CWE Flag Count\n",
      "Only 1 value :  ECE Flag Count\n",
      "Same Unique Values :  Fwd Avg Bytes/Bulk\n",
      "Only 1 value :  Fwd Avg Packets/Bulk\n",
      "Only 1 value :  Fwd Avg Bulk Rate\n",
      "Only 1 value :  Bwd Avg Bytes/Bulk\n",
      "Only 1 value :  Bwd Avg Packets/Bulk\n",
      "Only 1 value :  Bwd Avg Bulk Rate\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    if len(data[column].unique()) > 1:\n",
    "        count = 0\n",
    "        if str(data[column].unique()[0]) != str(data[column].unique()[1]):\n",
    "                count += 1\n",
    "        if (count == 0):\n",
    "            print('Same Unique Values : ',column)\n",
    "            data = data.drop(column, axis = 1)\n",
    "    elif len(data[column].unique()) == 1:\n",
    "        print('Only 1 value : ', column)\n",
    "        data = data.drop(column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca4ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Down/Up Ratio']  = [float(x) for x in data['Down/Up Ratio'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d341ebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Bwd Packet Length Min</th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Std</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Total</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Fwd PSH Flags</th>\n",
       "      <th>Fwd Header Length</th>\n",
       "      <th>Bwd Header Length</th>\n",
       "      <th>Fwd Packets/s</th>\n",
       "      <th>Bwd Packets/s</th>\n",
       "      <th>Min Packet Length</th>\n",
       "      <th>Max Packet Length</th>\n",
       "      <th>Packet Length Mean</th>\n",
       "      <th>Packet Length Std</th>\n",
       "      <th>Packet Length Variance</th>\n",
       "      <th>FIN Flag Count</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Fwd Header Length.1</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264525</th>\n",
       "      <td>0</td>\n",
       "      <td>10.42.0.151-40.69.219.199-35131-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>35131</td>\n",
       "      <td>40.69.219.199</td>\n",
       "      <td>443.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12109</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>60.104076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7019.572219</td>\n",
       "      <td>165.166405</td>\n",
       "      <td>12109.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>165.166405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>49.074773</td>\n",
       "      <td>2408.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android_SMS_Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264526</th>\n",
       "      <td>1</td>\n",
       "      <td>10.42.0.151-40.69.219.199-35131-443-6</td>\n",
       "      <td>40.69.219.199</td>\n",
       "      <td>443</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>35131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46511.627907</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>46511.627907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android_SMS_Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264527</th>\n",
       "      <td>2</td>\n",
       "      <td>10.42.0.151-40.122.44.96-54930-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>54930</td>\n",
       "      <td>40.122.44.96</td>\n",
       "      <td>443.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>60.104076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5790.979698</td>\n",
       "      <td>136.258346</td>\n",
       "      <td>14678.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>14678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>136.258346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>49.074773</td>\n",
       "      <td>2408.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android_SMS_Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264528</th>\n",
       "      <td>3</td>\n",
       "      <td>10.42.0.151-40.122.44.96-54930-443-6</td>\n",
       "      <td>40.122.44.96</td>\n",
       "      <td>443</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>54930.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46511.627907</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>46511.627907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android_SMS_Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264529</th>\n",
       "      <td>4</td>\n",
       "      <td>10.42.0.151-52.179.153.195-53215-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>53215</td>\n",
       "      <td>52.179.153.195</td>\n",
       "      <td>443.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3355709</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.272727</td>\n",
       "      <td>263.158542</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>775.714286</td>\n",
       "      <td>672.413245</td>\n",
       "      <td>2002.557433</td>\n",
       "      <td>5.363993</td>\n",
       "      <td>197394.647059</td>\n",
       "      <td>653868.357763</td>\n",
       "      <td>2731778.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3355709.0</td>\n",
       "      <td>335570.9</td>\n",
       "      <td>843621.265168</td>\n",
       "      <td>2731778.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>542766.0</td>\n",
       "      <td>90461.0</td>\n",
       "      <td>100811.101629</td>\n",
       "      <td>200127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360</td>\n",
       "      <td>232</td>\n",
       "      <td>3.277996</td>\n",
       "      <td>2.085997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>353.684211</td>\n",
       "      <td>547.317403</td>\n",
       "      <td>299556.339181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373.333333</td>\n",
       "      <td>117.272727</td>\n",
       "      <td>775.714286</td>\n",
       "      <td>360.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android_SMS_Malware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                 Flow ID      Source IP  \\\n",
       "264525           0   10.42.0.151-40.69.219.199-35131-443-6    10.42.0.151   \n",
       "264526           1   10.42.0.151-40.69.219.199-35131-443-6  40.69.219.199   \n",
       "264527           2    10.42.0.151-40.122.44.96-54930-443-6    10.42.0.151   \n",
       "264528           3    10.42.0.151-40.122.44.96-54930-443-6   40.122.44.96   \n",
       "264529           4  10.42.0.151-52.179.153.195-53215-443-6    10.42.0.151   \n",
       "\n",
       "        Source Port  Destination IP  Destination Port  Protocol  \\\n",
       "264525        35131   40.69.219.199             443.0       6.0   \n",
       "264526          443     10.42.0.151           35131.0       6.0   \n",
       "264527        54930    40.122.44.96             443.0       6.0   \n",
       "264528          443     10.42.0.151           54930.0       6.0   \n",
       "264529        53215  52.179.153.195             443.0       6.0   \n",
       "\n",
       "        Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "264525          12109                  2                       0   \n",
       "264526             43                  2                       0   \n",
       "264527          14678                  2                       0   \n",
       "264528             43                  2                       0   \n",
       "264529        3355709                 11                       7   \n",
       "\n",
       "        Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "264525                         85.0                          0.0   \n",
       "264526                          0.0                          0.0   \n",
       "264527                         85.0                          0.0   \n",
       "264528                          0.0                          0.0   \n",
       "264529                       1290.0                       5430.0   \n",
       "\n",
       "        Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "264525                   85.0                    0.0               42.500000   \n",
       "264526                    0.0                    0.0                0.000000   \n",
       "264527                   85.0                    0.0               42.500000   \n",
       "264528                    0.0                    0.0                0.000000   \n",
       "264529                  869.0                    0.0              117.272727   \n",
       "\n",
       "        Fwd Packet Length Std  Bwd Packet Length Max  Bwd Packet Length Min  \\\n",
       "264525              60.104076                    0.0                    0.0   \n",
       "264526               0.000000                    0.0                    0.0   \n",
       "264527              60.104076                    0.0                    0.0   \n",
       "264528               0.000000                    0.0                    0.0   \n",
       "264529             263.158542                 1448.0                    0.0   \n",
       "\n",
       "        Bwd Packet Length Mean  Bwd Packet Length Std  Flow Bytes/s  \\\n",
       "264525                0.000000               0.000000   7019.572219   \n",
       "264526                0.000000               0.000000      0.000000   \n",
       "264527                0.000000               0.000000   5790.979698   \n",
       "264528                0.000000               0.000000      0.000000   \n",
       "264529              775.714286             672.413245   2002.557433   \n",
       "\n",
       "        Flow Packets/s  Flow IAT Mean   Flow IAT Std  Flow IAT Max  \\\n",
       "264525      165.166405   12109.000000       0.000000       12109.0   \n",
       "264526    46511.627907      43.000000       0.000000          43.0   \n",
       "264527      136.258346   14678.000000       0.000000       14678.0   \n",
       "264528    46511.627907      43.000000       0.000000          43.0   \n",
       "264529        5.363993  197394.647059  653868.357763     2731778.0   \n",
       "\n",
       "        Flow IAT Min  Fwd IAT Total  Fwd IAT Mean    Fwd IAT Std  Fwd IAT Max  \\\n",
       "264525       12109.0        12109.0       12109.0       0.000000      12109.0   \n",
       "264526          43.0           43.0          43.0       0.000000         43.0   \n",
       "264527       14678.0        14678.0       14678.0       0.000000      14678.0   \n",
       "264528          43.0           43.0          43.0       0.000000         43.0   \n",
       "264529           6.0      3355709.0      335570.9  843621.265168    2731778.0   \n",
       "\n",
       "        Fwd IAT Min  Bwd IAT Total  Bwd IAT Mean    Bwd IAT Std  Bwd IAT Max  \\\n",
       "264525      12109.0            0.0           0.0       0.000000          0.0   \n",
       "264526         43.0            0.0           0.0       0.000000          0.0   \n",
       "264527      14678.0            0.0           0.0       0.000000          0.0   \n",
       "264528         43.0            0.0           0.0       0.000000          0.0   \n",
       "264529         13.0       542766.0       90461.0  100811.101629     200127.0   \n",
       "\n",
       "        Bwd IAT Min  Fwd PSH Flags  Fwd Header Length  Bwd Header Length  \\\n",
       "264525          0.0            1.0                 64                  0   \n",
       "264526          0.0            0.0                 64                  0   \n",
       "264527          0.0            1.0                 64                  0   \n",
       "264528          0.0            0.0                 64                  0   \n",
       "264529          6.0            0.0                360                232   \n",
       "\n",
       "        Fwd Packets/s  Bwd Packets/s  Min Packet Length  Max Packet Length  \\\n",
       "264525     165.166405       0.000000                0.0               85.0   \n",
       "264526   46511.627907       0.000000                0.0                0.0   \n",
       "264527     136.258346       0.000000                0.0               85.0   \n",
       "264528   46511.627907       0.000000                0.0                0.0   \n",
       "264529       3.277996       2.085997                0.0             1448.0   \n",
       "\n",
       "        Packet Length Mean  Packet Length Std  Packet Length Variance  \\\n",
       "264525           56.666667          49.074773             2408.333333   \n",
       "264526            0.000000           0.000000                0.000000   \n",
       "264527           56.666667          49.074773             2408.333333   \n",
       "264528            0.000000           0.000000                0.000000   \n",
       "264529          353.684211         547.317403           299556.339181   \n",
       "\n",
       "        FIN Flag Count  SYN Flag Count  PSH Flag Count  ACK Flag Count  \\\n",
       "264525             0.0             1.0             0.0             1.0   \n",
       "264526             0.0             0.0             0.0             1.0   \n",
       "264527             0.0             1.0             0.0             1.0   \n",
       "264528             0.0             0.0             0.0             1.0   \n",
       "264529             0.0             0.0             1.0             0.0   \n",
       "\n",
       "        URG Flag Count  Down/Up Ratio  Average Packet Size  \\\n",
       "264525             0.0            0.0            85.000000   \n",
       "264526             0.0            0.0             0.000000   \n",
       "264527             0.0            0.0            85.000000   \n",
       "264528             0.0            0.0             0.000000   \n",
       "264529             0.0            0.0           373.333333   \n",
       "\n",
       "        Avg Fwd Segment Size  Avg Bwd Segment Size  Fwd Header Length.1  \\\n",
       "264525             42.500000              0.000000                 64.0   \n",
       "264526              0.000000              0.000000                 64.0   \n",
       "264527             42.500000              0.000000                 64.0   \n",
       "264528              0.000000              0.000000                 64.0   \n",
       "264529            117.272727            775.714286                360.0   \n",
       "\n",
       "        Subflow Fwd Packets  Subflow Fwd Bytes  Subflow Bwd Packets  \\\n",
       "264525                  2.0               85.0                  0.0   \n",
       "264526                  2.0                0.0                  0.0   \n",
       "264527                  2.0               85.0                  0.0   \n",
       "264528                  2.0                0.0                  0.0   \n",
       "264529                 11.0             1290.0                  7.0   \n",
       "\n",
       "        Subflow Bwd Bytes  Init_Win_bytes_forward  Init_Win_bytes_backward  \\\n",
       "264525                0.0                  1550.0                     -1.0   \n",
       "264526                0.0                   510.0                     -1.0   \n",
       "264527                0.0                  1550.0                     -1.0   \n",
       "264528                0.0                   509.0                     -1.0   \n",
       "264529             5430.0                 65535.0                    510.0   \n",
       "\n",
       "        act_data_pkt_fwd  min_seg_size_forward  Active Mean  Active Std  \\\n",
       "264525               0.0                  32.0          0.0         0.0   \n",
       "264526               0.0                  32.0          0.0         0.0   \n",
       "264527               0.0                  32.0          0.0         0.0   \n",
       "264528               0.0                  32.0          0.0         0.0   \n",
       "264529               3.0                  32.0          0.0         0.0   \n",
       "\n",
       "        Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
       "264525         0.0         0.0        0.0       0.0       0.0       0.0   \n",
       "264526         0.0         0.0        0.0       0.0       0.0       0.0   \n",
       "264527         0.0         0.0        0.0       0.0       0.0       0.0   \n",
       "264528         0.0         0.0        0.0       0.0       0.0       0.0   \n",
       "264529         0.0         0.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "                      Label  \n",
       "264525  Android_SMS_Malware  \n",
       "264526  Android_SMS_Malware  \n",
       "264527  Android_SMS_Malware  \n",
       "264528  Android_SMS_Malware  \n",
       "264529  Android_SMS_Malware  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d886e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84a6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d988ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(['Label'], axis=1)\n",
    "y = [data['Label'].unique().tolist().index(i) for i in data['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf63f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Android_SMS_Malware' 'Benign']\n"
     ]
    }
   ],
   "source": [
    "print(data['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d9c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e68f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply target encoding only to training data\n",
    "encoder = TargetEncoder()\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train, y_train), columns=X_train.columns)\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fdebb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling only to training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_encoded), columns=X_train_encoded.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_encoded), columns=X_test_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18471187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.5s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.7s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.5s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.7s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  11.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  10.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  11.9s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  11.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  11.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  11.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  12.5s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  12.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  11.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  11.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.5s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.6s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  10.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.5s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.5s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.5s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  10.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  10.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  10.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  10.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  10.7s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  12.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  12.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  12.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  12.7s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  12.4s\n",
      "Best parameters for rf: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': 30}\n",
      "Classification report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     20218\n",
      "           1       0.98      0.58      0.73      7113\n",
      "\n",
      "    accuracy                           0.89     27331\n",
      "   macro avg       0.93      0.79      0.83     27331\n",
      "weighted avg       0.90      0.89      0.88     27331\n",
      "\n",
      "Confusion Matrix for rf:\n",
      "[[20138    80]\n",
      " [ 3022  4091]]\n",
      "\n",
      "AUC for rf: 0.96\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "Best parameters for dt: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 40}\n",
      "Classification report for dt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     20218\n",
      "           1       0.87      0.60      0.71      7113\n",
      "\n",
      "    accuracy                           0.87     27331\n",
      "   macro avg       0.87      0.78      0.81     27331\n",
      "weighted avg       0.87      0.87      0.86     27331\n",
      "\n",
      "Confusion Matrix for dt:\n",
      "[[19587   631]\n",
      " [ 2859  4254]]\n",
      "\n",
      "AUC for dt: 0.79\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.0s\n",
      "Best parameters for xgb: {'classifier__subsample': 0.6, 'classifier__n_estimators': 150, 'classifier__min_child_weight': 1, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.05, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}\n",
      "Classification report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     20218\n",
      "           1       0.98      0.57      0.72      7113\n",
      "\n",
      "    accuracy                           0.89     27331\n",
      "   macro avg       0.93      0.78      0.83     27331\n",
      "weighted avg       0.90      0.89      0.87     27331\n",
      "\n",
      "Confusion Matrix for xgb:\n",
      "[[20142    76]\n",
      " [ 3047  4066]]\n",
      "\n",
      "AUC for xgb: 0.93\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.3s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   7.1s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   2.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   2.7s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   2.7s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   2.5s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.8s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.9s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.9s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.9s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.9s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for lr: {'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__l1_ratio': 0.1, 'classifier__C': 0.1}\n",
      "Classification report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     20218\n",
      "           1       0.98      0.57      0.72      7113\n",
      "\n",
      "    accuracy                           0.89     27331\n",
      "   macro avg       0.93      0.78      0.83     27331\n",
      "weighted avg       0.90      0.89      0.87     27331\n",
      "\n",
      "Confusion Matrix for lr:\n",
      "[[20156    62]\n",
      " [ 3057  4056]]\n",
      "\n",
      "AUC for lr: 0.96\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting up the pipelines for each classifier\n",
    "pipelines = {\n",
    "    'rf': Pipeline([('classifier', RandomForestClassifier(random_state=42))]),\n",
    "    'dt': Pipeline([('classifier', DecisionTreeClassifier(random_state=42))]),\n",
    "    'xgb': Pipeline([('classifier', XGBClassifier(random_state=42))]),\n",
    "    'lr': Pipeline([('classifier', LogisticRegression(random_state=42))])\n",
    "}\n",
    "\n",
    "# Hyperparameter space for each classifier\n",
    "param_distributions = {\n",
    "    'rf': {\n",
    "        'classifier__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    'dt': {\n",
    "        'classifier__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    'xgb': {\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7, 10],\n",
    "        'classifier__min_child_weight': [1, 3, 5],\n",
    "        'classifier__gamma': [0, 0.1, 0.2, 0.5],\n",
    "        'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "        'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "       'lr': {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'classifier__solver': ['saga'],\n",
    "        'classifier__l1_ratio': [0.1, 0.5, 0.7, 1]  # This is only used if penalty is 'elasticnet'\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "roc_auc_scores = {}\n",
    "plt.figure()\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    search = RandomizedSearchCV(pipeline, param_distributions[model_name], n_iter=10, cv=5, verbose=2, random_state=42)\n",
    "    search.fit(X_train_scaled, y_train)\n",
    "    best_estimators[model_name] = search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "    \n",
    "    # Predict probabilities for the test data\n",
    "    y_probs = search.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = search.predict(X_test_scaled)\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_scores[model_name] = roc_auc\n",
    "    \n",
    "     # Aggregate ROC curve data for each model\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Print Classification Report\n",
    "    print(f\"Classification report for {model_name}:\\n{classification_report(y_test, y_pred)}\")\n",
    "    # Print Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for {model_name}:\\n{cm}\\n\")\n",
    "    \n",
    "    # Print AUC\n",
    "    print(f\"AUC for {model_name}: {roc_auc:.2f}\\n\")\n",
    "    # Finalizing the ROC plot\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92c906",
   "metadata": {},
   "source": [
    "# Applying SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f13992d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b7c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e7668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 47176, 1: 47176})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each class in y_train_smote\n",
    "class_counts = Counter(y_train_smote)\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3928a",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2421acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_selected_features = ['Flow IAT Mean', 'Average Packet Size', 'Subflow Bwd Bytes', 'Flow ID', 'Fwd Packet Length Mean', 'Bwd IAT Mean', 'Total Length of Fwd Packets', 'Down/Up Ratio', 'Bwd Packet Length Max', 'Flow Duration', 'Min Packet Length', 'Destination Port', 'Packet Length Mean', 'Bwd IAT Min', 'Fwd Packet Length Min', 'Source IP', 'Fwd Packet Length Std', 'Flow IAT Std', 'Bwd IAT Total', 'Idle Min', 'Flow Packets/s', 'Active Std']\n",
    "simulated_annealing_selected_features = ['Active Std', 'Packet Length Mean', 'Avg Bwd Segment Size', 'Subflow Bwd Packets', 'Total Fwd Packets', 'Idle Min', 'Average Packet Size', 'Subflow Bwd Bytes', 'Fwd Packet Length Mean', 'min_seg_size_forward', 'Idle Std', 'Fwd IAT Mean', 'Init_Win_bytes_backward', 'Bwd IAT Min', 'Fwd Packet Length Std', 'Active Max', 'Fwd Packet Length Min', 'act_data_pkt_fwd', 'Fwd IAT Std', 'Avg Fwd Segment Size', 'Source Port', 'Bwd IAT Total', 'Bwd Packet Length Std', 'Max Packet Length', 'Fwd Packet Length Max', 'Source IP', 'Fwd IAT Max', 'Flow IAT Std', 'Bwd Packets/s', 'Destination IP', 'Protocol', 'Total Backward Packets', 'Packet Length Std', 'Active Mean', 'Min Packet Length', 'Destination Port', 'URG Flag Count', 'Total Length of Bwd Packets', 'SYN Flag Count', 'PSH Flag Count', 'Bwd IAT Mean', 'Bwd Header Length', 'Fwd Header Length', 'Total Length of Fwd Packets', 'Down/Up Ratio', 'Bwd IAT Std', 'Flow Bytes/s', 'Fwd Header Length.1', 'Fwd IAT Min', 'Idle Max', 'Fwd IAT Total', 'Flow Duration', 'Idle Mean', 'Fwd PSH Flags']\n",
    "genetic_search_selected_features = [\n",
    "    'Source Port', 'min_seg_size_forward', 'Min Packet Length', 'Bwd Packet Length Std',\n",
    "    'Bwd IAT Mean', 'Fwd Packets/s', 'Bwd Packets/s', 'Total Length of Bwd Packets',\n",
    "    'Avg Bwd Segment Size', 'Init_Win_bytes_backward', 'Fwd IAT Max', 'Bwd IAT Max',\n",
    "    'Fwd Header Length.1', 'Protocol', 'Total Length of Fwd Packets', 'URG Flag Count',\n",
    "    'Fwd Packet Length Mean', 'Init_Win_bytes_forward', 'Bwd Packet Length Min',\n",
    "    'Fwd IAT Mean', 'Flow Bytes/s', 'Down/Up Ratio', 'Active Std', 'Avg Fwd Segment Size',\n",
    "    'Fwd IAT Total', 'Fwd Packet Length Std', 'Subflow Bwd Packets', 'Flow ID',\n",
    "    'Fwd Packet Length Max', 'Bwd IAT Min', 'Idle Min', 'Flow IAT Mean', 'Subflow Bwd Bytes',\n",
    "    'Bwd Packet Length Mean', 'Destination Port', 'Average Packet Size', 'Source IP',\n",
    "    'Active Min', 'Flow IAT Min', 'Fwd Packet Length Min', 'Total Fwd Packets', 'Flow Packets/s',\n",
    "    'Fwd Header Length', 'Packet Length Variance', 'Bwd IAT Std', 'Subflow Fwd Packets'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6a2ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X_train, X_test, y_train, y_test, feature_set_name):\n",
    "    # Update X_train and X_test to include only the selected features\n",
    "    X_train_selected = X_train_smote[feature_set_name]\n",
    "    X_test_selected = X_test_scaled[feature_set_name]\n",
    "\n",
    "\n",
    "    best_estimators = {}\n",
    "    roc_auc_scores = {}\n",
    "    plt.figure()\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        search = RandomizedSearchCV(pipeline, param_distributions[model_name], n_iter=10, cv=5, verbose=2, random_state=42)\n",
    "        search.fit(X_train_selected, y_train)\n",
    "        best_estimators[model_name] = search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "        \n",
    "        # Predict probabilities for the test data\n",
    "        y_probs = search.predict_proba(X_test_selected)[:, 1]\n",
    "        y_pred = search.predict(X_test_selected)\n",
    "\n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc_scores[model_name] = roc_auc\n",
    "        \n",
    "         # Aggregate ROC curve data for each model\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        # Print Classification Report\n",
    "        print(f\"Classification report for {model_name}:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        # Print Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Confusion Matrix for {model_name}:\\n{cm}\\n\")\n",
    "        \n",
    "        # Print AUC\n",
    "        print(f\"AUC for {model_name}: {roc_auc:.2f}\\n\")\n",
    "    # Finalizing the ROC plot\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94ee4a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Search Selected Features\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   8.9s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   8.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   8.9s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   8.7s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.8s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   9.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   8.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   8.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.3s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.3s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.8s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   9.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   9.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   9.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   8.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   8.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   9.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   8.9s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   9.0s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   8.9s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   8.5s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   8.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   9.3s\n",
      "Best parameters for rf: {'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 50}\n",
      "Classification report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     20218\n",
      "           1       0.90      0.62      0.73      7113\n",
      "\n",
      "    accuracy                           0.88     27331\n",
      "   macro avg       0.89      0.80      0.83     27331\n",
      "weighted avg       0.88      0.88      0.87     27331\n",
      "\n",
      "Confusion Matrix for rf:\n",
      "[[19711   507]\n",
      " [ 2720  4393]]\n",
      "\n",
      "AUC for rf: 0.94\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.0s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "Best parameters for dt: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 40}\n",
      "Classification report for dt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     20218\n",
      "           1       0.71      0.72      0.72      7113\n",
      "\n",
      "    accuracy                           0.85     27331\n",
      "   macro avg       0.81      0.81      0.81     27331\n",
      "weighted avg       0.85      0.85      0.85     27331\n",
      "\n",
      "Confusion Matrix for dt:\n",
      "[[18130  2088]\n",
      " [ 1957  5156]]\n",
      "\n",
      "AUC for dt: 0.81\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   0.9s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   0.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.3s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   0.9s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.6s\n",
      "Best parameters for xgb: {'classifier__subsample': 0.8, 'classifier__n_estimators': 200, 'classifier__min_child_weight': 1, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}\n",
      "Classification report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     20218\n",
      "           1       0.74      0.69      0.71      7113\n",
      "\n",
      "    accuracy                           0.86     27331\n",
      "   macro avg       0.81      0.80      0.81     27331\n",
      "weighted avg       0.85      0.86      0.85     27331\n",
      "\n",
      "Confusion Matrix for xgb:\n",
      "[[18457  1761]\n",
      " [ 2197  4916]]\n",
      "\n",
      "AUC for xgb: 0.92\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   5.9s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   5.1s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.4s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.5s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.7s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for lr: {'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__l1_ratio': 1, 'classifier__C': 10}\n",
      "Classification report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     20218\n",
      "           1       0.96      0.58      0.73      7113\n",
      "\n",
      "    accuracy                           0.89     27331\n",
      "   macro avg       0.92      0.79      0.83     27331\n",
      "weighted avg       0.90      0.89      0.88     27331\n",
      "\n",
      "Confusion Matrix for lr:\n",
      "[[20063   155]\n",
      " [ 2970  4143]]\n",
      "\n",
      "AUC for lr: 0.94\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Evaluating Random Search Selected Features\")\n",
    "run_models(X_train_smote, X_test, y_train_smote, y_test, random_search_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a3e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Simulated Annealing Selected Features\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  21.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  21.8s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  29.8s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  29.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  29.5s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  30.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  29.6s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  22.0s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  27.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  27.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  27.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  27.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  27.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  28.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  28.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  28.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  28.5s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  28.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  17.9s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  17.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  17.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  17.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  17.5s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  22.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  23.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  22.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  22.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  22.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  13.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  13.3s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  13.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  13.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  13.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  23.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  22.9s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  23.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  23.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  23.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  30.0s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  30.5s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  31.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  29.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  29.3s\n",
      "Best parameters for rf: {'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 50}\n",
      "Classification report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     20218\n",
      "           1       0.72      0.74      0.73      7113\n",
      "\n",
      "    accuracy                           0.86     27331\n",
      "   macro avg       0.81      0.82      0.81     27331\n",
      "weighted avg       0.86      0.86      0.86     27331\n",
      "\n",
      "Confusion Matrix for rf:\n",
      "[[18149  2069]\n",
      " [ 1874  5239]]\n",
      "\n",
      "AUC for rf: 0.92\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.4s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.3s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.3s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.4s\n",
      "Best parameters for dt: {'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 50}\n",
      "Classification report for dt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     20218\n",
      "           1       0.63      0.69      0.66      7113\n",
      "\n",
      "    accuracy                           0.81     27331\n",
      "   macro avg       0.76      0.77      0.76     27331\n",
      "weighted avg       0.82      0.81      0.82     27331\n",
      "\n",
      "Confusion Matrix for dt:\n",
      "[[17328  2890]\n",
      " [ 2226  4887]]\n",
      "\n",
      "AUC for dt: 0.77\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   3.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   3.6s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   3.7s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   3.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.4s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   7.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   8.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   8.2s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   8.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   8.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.5s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.1s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.3s\n",
      "Best parameters for xgb: {'classifier__subsample': 0.8, 'classifier__n_estimators': 200, 'classifier__min_child_weight': 1, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}\n",
      "Classification report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     20218\n",
      "           1       0.76      0.76      0.76      7113\n",
      "\n",
      "    accuracy                           0.88     27331\n",
      "   macro avg       0.84      0.84      0.84     27331\n",
      "weighted avg       0.88      0.88      0.88     27331\n",
      "\n",
      "Confusion Matrix for xgb:\n",
      "[[18523  1695]\n",
      " [ 1685  5428]]\n",
      "\n",
      "AUC for xgb: 0.94\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  11.2s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.4s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.5s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.2s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.4s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.3s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.3s\n",
      "Best parameters for lr: {'classifier__solver': 'saga', 'classifier__penalty': 'elasticnet', 'classifier__l1_ratio': 0.7, 'classifier__C': 0.1}\n",
      "Classification report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81     20218\n",
      "           1       0.51      0.81      0.62      7113\n",
      "\n",
      "    accuracy                           0.75     27331\n",
      "   macro avg       0.71      0.77      0.72     27331\n",
      "weighted avg       0.81      0.75      0.76     27331\n",
      "\n",
      "Confusion Matrix for lr:\n",
      "[[14707  5511]\n",
      " [ 1382  5731]]\n",
      "\n",
      "AUC for lr: 0.85\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Evaluating Simulated Annealing Selected Features\")\n",
    "run_models(X_train_smote, X_test, y_train_smote, y_test, simulated_annealing_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706a9f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Genetic Search Selected Features\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  13.4s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.6s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.9s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.7s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.4s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  15.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  14.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  13.0s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.6s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.3s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.8s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=  12.6s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  14.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  14.0s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.7s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.6s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  13.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  13.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  13.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  14.0s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=  13.6s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  11.8s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  12.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  11.9s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  12.0s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  11.6s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  13.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  13.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  12.6s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  12.8s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=  12.7s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  10.8s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  10.8s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  10.5s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  10.5s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=  10.5s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  13.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.3s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.7s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=  12.7s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  13.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  13.8s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  14.5s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  13.6s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=  13.8s\n",
      "Best parameters for rf: {'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 50}\n",
      "Classification report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     20218\n",
      "           1       0.93      0.60      0.73      7113\n",
      "\n",
      "    accuracy                           0.88     27331\n",
      "   macro avg       0.90      0.79      0.83     27331\n",
      "weighted avg       0.89      0.88      0.88     27331\n",
      "\n",
      "Confusion Matrix for rf:\n",
      "[[19891   327]\n",
      " [ 2827  4286]]\n",
      "\n",
      "AUC for rf: 0.95\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=40, classifier__max_features=log2, classifier__min_samples_leaf=2, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=20, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=sqrt, classifier__min_samples_leaf=2, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=auto, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=10; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.1s\n",
      "[CV] END classifier__max_depth=30, classifier__max_features=log2, classifier__min_samples_leaf=1, classifier__min_samples_split=5; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.2s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.1s\n",
      "[CV] END classifier__max_depth=50, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=2; total time=   0.2s\n",
      "Best parameters for dt: {'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 30}\n",
      "Classification report for dt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87     20218\n",
      "           1       0.61      0.73      0.66      7113\n",
      "\n",
      "    accuracy                           0.81     27331\n",
      "   macro avg       0.75      0.78      0.76     27331\n",
      "weighted avg       0.82      0.81      0.81     27331\n",
      "\n",
      "Confusion Matrix for dt:\n",
      "[[16877  3341]\n",
      " [ 1916  5197]]\n",
      "\n",
      "AUC for dt: 0.79\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=10, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=50, classifier__subsample=1.0; total time=   0.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=5, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   2.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.01, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.8; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.2s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.2, classifier__learning_rate=0.1, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=100, classifier__subsample=0.8; total time=   1.3s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.6s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.7s\n",
      "[CV] END classifier__colsample_bytree=0.8, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=5, classifier__min_child_weight=5, classifier__n_estimators=150, classifier__subsample=1.0; total time=   1.8s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.2, classifier__max_depth=10, classifier__min_child_weight=1, classifier__n_estimators=200, classifier__subsample=0.8; total time=   3.5s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.2, classifier__learning_rate=0.2, classifier__max_depth=7, classifier__min_child_weight=1, classifier__n_estimators=50, classifier__subsample=0.8; total time=   1.0s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.3s\n",
      "[CV] END classifier__colsample_bytree=0.6, classifier__gamma=0, classifier__learning_rate=0.2, classifier__max_depth=3, classifier__min_child_weight=5, classifier__n_estimators=200, classifier__subsample=0.8; total time=   2.4s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "[CV] END classifier__colsample_bytree=1.0, classifier__gamma=0.1, classifier__learning_rate=0.05, classifier__max_depth=3, classifier__min_child_weight=1, classifier__n_estimators=150, classifier__subsample=0.6; total time=   1.9s\n",
      "Best parameters for xgb: {'classifier__subsample': 0.8, 'classifier__n_estimators': 200, 'classifier__min_child_weight': 1, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}\n",
      "Classification report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91     20218\n",
      "           1       0.77      0.68      0.72      7113\n",
      "\n",
      "    accuracy                           0.86     27331\n",
      "   macro avg       0.83      0.80      0.81     27331\n",
      "weighted avg       0.86      0.86      0.86     27331\n",
      "\n",
      "Confusion Matrix for xgb:\n",
      "[[18731  1487]\n",
      " [ 2269  4844]]\n",
      "\n",
      "AUC for xgb: 0.93\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  10.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=l2, classifier__solver=saga; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.7, classifier__penalty=l2, classifier__solver=saga; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=100, classifier__l1_ratio=1, classifier__penalty=elasticnet, classifier__solver=saga; total time=   9.8s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.1, classifier__penalty=l2, classifier__solver=saga; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=1, classifier__penalty=none, classifier__solver=saga; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=10, classifier__l1_ratio=0.5, classifier__penalty=l2, classifier__solver=saga; total time=   8.0s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.7s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.6s\n",
      "[CV] END classifier__C=0.1, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.1, classifier__penalty=l1, classifier__solver=saga; total time=   0.7s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.0s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.0s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.0s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   0.8s\n",
      "[CV] END classifier__C=0.001, classifier__l1_ratio=0.7, classifier__penalty=elasticnet, classifier__solver=saga; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for lr: {'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__l1_ratio': 1, 'classifier__C': 10}\n",
      "Classification report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     20218\n",
      "           1       0.96      0.58      0.73      7113\n",
      "\n",
      "    accuracy                           0.89     27331\n",
      "   macro avg       0.92      0.79      0.83     27331\n",
      "weighted avg       0.90      0.89      0.88     27331\n",
      "\n",
      "Confusion Matrix for lr:\n",
      "[[20063   155]\n",
      " [ 2968  4145]]\n",
      "\n",
      "AUC for lr: 0.94\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Evaluating Genetic Search Selected Features\")\n",
    "run_models(X_train_smote, X_test, y_train_smote, y_test, genetic_search_selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
